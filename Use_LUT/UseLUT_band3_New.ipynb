{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "YYYY = '2018'\n",
    "MM = ['01']\n",
    "DD = ['07']\n",
    "MIN = ['20']\n",
    "HH = ['06']\n",
    "\n",
    "target ='/media/liwei/Data/AHI_AC_RESULT/'\n",
    "SZA_PATH = '/media/liwei/Data/Solar_zenith_angle/'\n",
    "SAZ_PATH = '/media/liwei/Data/Solar_azimuth_angle/'\n",
    "VZA_PATH = '/media/liwei/Data/AHI_Angle/AHI_VZA_05.dat'\n",
    "VAA_PATH = '/media/liwei/Data/AHI_Angle/AHI_VAA_05.dat'\n",
    "LUT_PATH = '/media/liwei/Data/LUT/'\n",
    "CAMS_PATH = '/media/liwei/Data/CAMS/'\n",
    "DN_PATH = '/media/liwei/Data/'\n",
    "CAMS_AERO_PATH = '' \n",
    "\n",
    "\n",
    "res = 0.005\n",
    "u_lat,d_lat = 60,-60\n",
    "l_lon,r_lon = 85,205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Py6S import *\n",
    "import time as T\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import griddata,interpn,RegularGridInterpolator\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import cv2\n",
    "from ftplib import FTP\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import multiprocessing\n",
    "import paramiko\n",
    "from scp import SCPClient\n",
    "import subprocess\n",
    "import datetime as dt\n",
    "   \n",
    "class H8_data:\n",
    "\n",
    "    def __init__(self , account , pw , band , band_number , date):\n",
    "        self.account = account\n",
    "        self.pw = pw\n",
    "        self.band = band\n",
    "        self.band_number = band_number\n",
    "        self.date = date\n",
    "    \n",
    "    def get_path(self):\n",
    "        return '/data01/GEO/ORGDATA/H8AHI/hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105' + self.date[0:6] + '/' + self.band.upper() + '/'\n",
    "\n",
    "    def get_filename(self):\n",
    "        return self.date + \".\" + self.band + \".\" + self.band_number + \".fld.geoss.bz2\"\n",
    "    \n",
    "    def DN2TBB(self,data):\n",
    "        LUT=np.loadtxt(DN_PATH + 'count2tbb_v102/' + self.band + \".\" + self.band_number)\n",
    "        return LUT[data,1]\n",
    "    \n",
    "    def file_path(self):\n",
    "        return self.get_path() + self.get_filename() \n",
    "                 \n",
    "    def download_H8data(self):\n",
    "        client = paramiko.SSHClient()\n",
    "        client.load_system_host_keys()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        client.connect(hostname='10.4.123.47', port=22, username=self.account, password=self.pw)\n",
    "        scp = SCPClient(client.get_transport())\n",
    "        sftp = client.open_sftp()\n",
    "\n",
    "        try :\n",
    "            sftp.stat(self.file_path())\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"File Not Found\")\n",
    "            return 'No data'\n",
    "\n",
    "        else:\n",
    "            scp.get(self.file_path(), folder_original+'/')\n",
    "            p = subprocess.Popen('lbzip2 -d {}{}'.format(folder_original+'/',self.file_path()[-33:]),shell=True)\n",
    "            p.communicate()\n",
    "            print ('Himawari8/AHI data Processed Finish')\n",
    "            return folder_original + '/' + self.get_filename()[:-4]\n",
    "            \n",
    "    def read_H8data(self):\n",
    "        H8_file_path = self.download_H8data()\n",
    "        if self.band == \"vis\":\n",
    "            sr = 12000\n",
    "        elif self.band == \"ext\":\n",
    "            sr = 24000\n",
    "        else:\n",
    "            sr = 6000\n",
    "        if H8_file_path != 'No data':\n",
    "            with open(H8_file_path,'rb') as fp:\n",
    "                data = np.frombuffer(fp.read(),dtype='>u2').reshape(sr,sr)\n",
    "                data = self.DN2TBB(data)\n",
    "                data = data/100\n",
    "\n",
    "            print(\"data reading finish\")\n",
    "            return data[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "        else:\n",
    "            return 'No data'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class JAXA_data:\n",
    "#     def __init__(self,account,YYYY,MM,DD,HH):\n",
    "#         self.account = account\n",
    "#         self.YYYY = YYYY\n",
    "#         self.MM = MM\n",
    "#         self.DD = DD\n",
    "#         self.HH = HH\n",
    "        \n",
    "#     def download_JAXA(self):\n",
    "#         ftp_addr = 'ftp.ptree.jaxa.jp'\n",
    "#         f=FTP(ftp_addr)\n",
    "#         f.login(self.account,'SP+wari8')\n",
    "#         remote_filepath = '/pub/model/ARP/MS/bet/' + self.YYYY + self.MM + '/' + self.DD + '/'\n",
    "#         f.cwd(remote_filepath)\n",
    "#         list=f.nlst()\n",
    "#         bufsize=1024\n",
    "#         for name in list:\n",
    "#             if name[13:17]== self.HH + '00':\n",
    "#                 data=open(folder_original + name ,'wb')\n",
    "#                 filename='RETR '+ name\n",
    "#                 f.retrbinary(filename,data.write,bufsize)\n",
    "#                 f.quit()\n",
    "#                 return folder_original + name\n",
    "    \n",
    "    \n",
    "#     def read_JAXA(self):\n",
    "#         AOT_path = self.download_JAXA()\n",
    "#         ds = xr.open_dataset(AOT_path)\n",
    "cd \n",
    "#         aot550=ds['od550aer']\n",
    "#         AOT550=aot550.interp(lon=lon_y,lat=lat_x,method=\"nearest\")\n",
    "#         AOT550=AOT550.values\n",
    "#         AOT550[AOT550>=max(AOT)] = max(AOT)-(1/10000)\n",
    "#         AOT550[AOT550<=min(AOT)] = min(AOT)+(1/10000)\n",
    "    \n",
    "        \n",
    "#         bc = ds['od550bc'].interp(lon=lon_y,lat=lat_x,method=\"nearest\")\n",
    "#         so4 = ds['od550so4'].interp(lon=lon_y,lat=lat_x,method=\"nearest\")\n",
    "#         oa = ds['od550oa'].interp(lon=lon_y,lat=lat_x,method=\"nearest\")\n",
    "#         dust = ds['od550dust'].interp(lon=lon_y,lat=lat_x,method=\"nearest\")\n",
    "#         ss = ds['od550ss'].interp(lon=lon_y,lat=lat_x,method=\"nearest\")\n",
    "        \n",
    "        \n",
    "#         DL_6S = np.array(dust).reshape(row_AHI,col_AHI)\n",
    "#         SL_6S = np.array(so4).reshape(row_AHI,col_AHI) + np.array(bc).reshape(row_AHI,col_AHI)\n",
    "#         OC_6S = np.array(ss).reshape(row_AHI,col_AHI)\n",
    "#         WS_6S = np.array(oa).reshape(row_AHI,col_AHI)\n",
    "\n",
    "#         Total = DL_6S + SL_6S + OC_6S + WS_6S\n",
    "\n",
    "#         precent_DL_6S = DL_6S / Total\n",
    "#         precent_SL_6S = SL_6S / Total\n",
    "#         precent_OC_6S = OC_6S / Total\n",
    "#         precent_WS_6S = WS_6S / Total\n",
    "#         P = np.dstack((precent_DL_6S,precent_WS_6S,precent_OC_6S,precent_SL_6S))\n",
    "        \n",
    "#         Aerosol_type = np.full((row_AHI,col_AHI),np.nan)\n",
    "        \n",
    "#         for i in range(row_AHI):\n",
    "#             for j in range(col_AHI):\n",
    "#                 if max(P[i,j,:]) == precent_OC_6S[i,j]:\n",
    "#                     Aerosol_type[i,j] = 1\n",
    "#                 else:\n",
    "#                     Aerosol_type[i,j] = 0\n",
    "                    \n",
    "#         return np.array(AOT550).reshape(row_AHI,col_AHI),Aerosol_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LUT_interpolation:\n",
    "    def __init__(self,LUT_PATH):\n",
    "        self.LUT_path = LUT_PATH\n",
    "    \n",
    "    def LUT_interpolation(self):\n",
    "        X1 = np.loadtxt(self.LUT_path + \"01_band3.csv\",delimiter=\",\").reshape(2,8,5,12,5,17,17,19)\n",
    "        Χ2 = np.loadtxt(self.LUT_path + \"02_band3.csv\",delimiter=\",\").reshape(2,8,5,12,5,17,17,19)\n",
    "        Χ3 = np.loadtxt(self.LUT_path + \"03_band3.csv\",delimiter=\",\").reshape(2,8,5,12,5,17,17,19)\n",
    "        \n",
    "\n",
    "        del X1,X2,X3,output\n",
    "\n",
    "        sza_new = np.linspace(0,80,161)\n",
    "        vza_new = np.linspace(0,80,161)\n",
    "\n",
    "        fn1 = RegularGridInterpolator((aero_type,water,ozone,AOT,AL,sza,vza,raa),X1,bounds_error=False,fill_value=np.nan)\n",
    "        fn2 = RegularGridInterpolator((aero_type,water,ozone,AOT,AL,sza,vza,raa),X2,bounds_error=False,fill_value=np.nan)\n",
    "        fn3 = RegularGridInterpolator((aero_type,water,ozone,AOT,AL,sza,vza,raa),X3,bounds_error=False,fill_value=np.nan)\n",
    "\n",
    "        return fn1,fn2,fn3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AHI_angle:\n",
    "    def __init__(self,date):\n",
    "        self.date = date        \n",
    "    def read_angle_data(self):\n",
    "        \n",
    "        AHI_date = self.date[4:11]\n",
    "        \n",
    "        sza_file_name = 'solar_zM_2020{}5.dat'.format(AHI_date)\n",
    "        saa_file_name = 'solar_aM_2020{}5.dat'.format(AHI_date)\n",
    "        \n",
    "        with open(SZA_PATH + sza_file_name,'wb') as fp:\n",
    "            AHI_SZA = np.frombuffer(fp.read(),dtype='>f4').reshape(3000,3000)[row_u_4KM:row_u_4KM + row_4KM , col_l_4KM:col_l_4KM + col_4KM]\n",
    "            AHI_SZA=cv2.resize(np.array(AHI_angle,dtype='float64'),(row_AHI,col_AHI),interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        with open(SAA_PATH + saa_file_name,'wb') as fp:\n",
    "            AHI_SAA = np.frombuffer(fp.read(),dtype='>f4').reshape(3000,3000)[row_u_4KM:row_u_4KM + row_4KM , col_l_4KM:col_l_4KM + col_4KM]\n",
    "            AHI_SAA=cv2.resize(np.array(AHI_angle,dtype='float64'),(row_AHI,col_AHI),interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        return AHI_SZA,AHI_SAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# class AHI_angle:\n",
    "#     def __init__(self,date,angle):\n",
    "#         self.date = date\n",
    "#         self.angle = angle\n",
    "        \n",
    "#     def download_AHI_angle(self):\n",
    "\n",
    "#         date1 = self.date[0:6]\n",
    "#         date2 = self.date[0:8]\n",
    "#         AHI_date = self.date\n",
    "        \n",
    "#         sza_file_name = '{}.sun.zth.fld.4km.bin.bz2'.format(AHI_date)\n",
    "#         saa_file_name = '{}.sun.azm.fld.4km.bin.bz2'.format(AHI_date)\n",
    "\n",
    "\n",
    "#         if self.angle == 'sza':\n",
    "#             if os.path.exists(folder_original + sza_file_name[:-4]):\n",
    "#                 return sza_file_name[:-4]\n",
    "\n",
    "#             else:\n",
    "#                 ftp = FTP()\n",
    "#                 ftp.connect('hmwr829gr.cr.chiba-u.ac.jp', 21)\n",
    "#                 ftp.login()\n",
    "#                 path = '/gridded/FD/V20190123/{}/4KM/{}/'.format(date1,date2)\n",
    "#                 ftp.cwd(path)\n",
    "#                 remote_list=ftp.nlst()\n",
    "#                 bufsize=1024*1024\n",
    "#                 if sza_file_name in remote_list:\n",
    "#                     data = open(folder_original + sza_file_name,'wb')\n",
    "#                     filename='RETR '+ sza_file_name\n",
    "#                     ftp.retrbinary(filename,data.write,bufsize)\n",
    "#                     ftp.quit()\n",
    "\n",
    "#                     return sza_file_name[:-4]\n",
    "#                 else:\n",
    "#     #                 print('AHI NO DATA')\n",
    "#                     return None\n",
    "\n",
    "#         elif self.angle == 'saa':\n",
    "#             if os.path.exists(folder_original + saa_file_name[:-4]):\n",
    "#                 return saa_file_name[:-4]\n",
    "\n",
    "#             else:\n",
    "#                 ftp = FTP()\n",
    "#                 ftp.connect('hmwr829gr.cr.chiba-u.ac.jp', 21)\n",
    "#                 ftp.login()\n",
    "#                 path = '/gridded/FD/V20190123/{}/4KM/{}/'.format(date1,date2)\n",
    "#                 ftp.cwd(path)\n",
    "#                 remote_list=ftp.nlst()\n",
    "#                 bufsize=1024*1024\n",
    "#                 if saa_file_name in remote_list:\n",
    "#                     data = open(folder_original + saa_file_name,'wb')\n",
    "#                     filename='RETR '+ saa_file_name\n",
    "#                     ftp.retrbinary(filename,data.write,bufsize)\n",
    "#                     ftp.quit()\n",
    "#                     return saa_file_name[:-4]\n",
    "#                 else:\n",
    "#     #                 print('AHI NO DATA')\n",
    "#                     return 'No data'\n",
    "    \n",
    "#     def Decompression(self,fn):\n",
    "#         if os.path.exists('{}.bz2'.format(folder_original + fn)):\n",
    "#             p = subprocess.Popen('lbzip2 -d {}.bz2'.format(folder_original + fn),shell=True)\n",
    "#             p.communicate()\n",
    "        \n",
    "        \n",
    "#     def read_AHI_solar_angle(self):\n",
    "#         return_code = self.download_AHI_angle()\n",
    "#         if return_code != 'No data':\n",
    "#             self.Decompression(return_code)\n",
    "#             with open(folder_original + return_code, 'rb' ) as fp:\n",
    "#                 AHI_angle = np.frombuffer(fp.read(),dtype='>f4').reshape(3000,3000)[row_u_4KM:row_u_4KM + row_4KM , col_l_4KM:col_l_4KM + col_4KM]\n",
    "#             AHI_angle=cv2.resize(np.array(AHI_angle,dtype='float64'),(row_AHI,col_AHI),interpolation=cv2.INTER_NEAREST)\n",
    "#             return AHI_angle\n",
    "#         else:\n",
    "#             return 'No data'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAMS_data:\n",
    "    def __init__(self,YYYY,MM,DD,HH,MIN):\n",
    "        self.YYYY = YYYY\n",
    "        self.MM = MM\n",
    "        self.DD = DD\n",
    "        self.HH = HH\n",
    "        self.MIN = MIN\n",
    "        \n",
    "    def read_CAMS(self):\n",
    "        \n",
    "        dt = dt.datetime(int(self.YYYY),int(self.MM),int(self.DD),int(self.HH),int(self.MIN)+5)\n",
    "        ds = xr.open_dataset(CAMS_PATH + self.YYYY + self.MM + self.DD + '.nc')\n",
    "        ds = ds.interp(time = dtime,method = 'linear')\n",
    "        ds = ds.interp(longitude=lon_y,latitude=lat_x,method=\"nearest\")\n",
    "        \n",
    "        OZ=ds['gtco3'].values        \n",
    "        WV=ds['tcwv'].values        \n",
    "        AOT550=ds['aod550'].values\n",
    "#         Atmosphere data Unit conversion\n",
    "        WV = WV/10\n",
    "        OZ = OZ*46.6975764\n",
    "\n",
    "\n",
    "#         Processing water vapor and ozone max and min\n",
    "        OZ[OZ>=max(ozone)] = max(ozone)-(1/10000)\n",
    "        OZ[OZ<=min(ozone)] = min(ozone)+(1/10000)\n",
    "        WV[WV>=max(water)] = max(water)-(1/10000)\n",
    "        WV[WV<=min(water)] = min(water)+(1/10000)\n",
    "        AOT550[AOT550>=max(AOT)] = max(AOT)-(1/10000)\n",
    "        AOT550[AOT550<=min(AOT)] = min(AOT)+(1/10000)\n",
    "        return np.array(OZ).reshape(row_AHI,col_AHI),np.array(WV).reshape(row_AHI,col_AHI),np.array(AOT550).reshape(row_AHI,col_AHI)\n",
    "\n",
    "    def read_CAMS_AERO(self):\n",
    "        \n",
    "        dt = dt.datetime(int(self.YYYY),int(self.MM),int(self.DD),int(self.HH),int(self.MIN)+5)\n",
    "        ds = xr.open_dataset(CAMS_AERO_PATH + self.YYYY + self.MM + self.DD + '.nc')\n",
    "        ds = ds.interp(time = dtime,method = 'linear')\n",
    "        ds = ds.interp(longitude=lon_y,latitude=lat_x,method=\"nearest\")\n",
    "        \n",
    "        bc = ds['bcaod550'].values\n",
    "        du = ds['duaod550'].values\n",
    "        om = ds['omaod550'].values\n",
    "        ss = ds['ssaod550'].valuescl\n",
    "        su = ds['suaod550'].values\n",
    "\n",
    "        DL_6S = np.array(du)\n",
    "        SL_6S = np.array(su) + np.array(bc)\n",
    "        OC_6S = np.array(ss)\n",
    "        WS_6S = np.array(om)\n",
    "\n",
    "        Total = DL_6S + SL_6S + OC_6S + WS_6S\n",
    "\n",
    "        precent_DL_6S = DL_6S / Total\n",
    "        precent_SL_6S = SL_6S / Total\n",
    "        precent_OC_6S = OC_6S / Total\n",
    "        precent_WS_6S = WS_6S / Total\n",
    "        P = np.dstack((precent_DL_6S,precent_WS_6S,precent_OC_6S,precent_SL_6S))\n",
    "        Aerosol_type = np.where(np.amax(P,axis = 2) == precent_OC_6S,1,0)\n",
    "        \n",
    "        return Aerosol_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "/media/liwei/Data/LUT/Continental_01_band3.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2dde59756f3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0mcol_l_4KM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_lon\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m85\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0.04\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m \u001b[0mfn1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLUT_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLUT_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLUT_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVZA_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2dde59756f3f>\u001b[0m in \u001b[0;36mLUT_interpolation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLUT_interpolation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mContinental_X1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLUT_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Continental_01_band3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0mContinental_X2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLUT_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Continental_02_band3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mContinental_X3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLUT_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"Continental_03_band3.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0mline_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    530\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: /media/liwei/Data/LUT/Continental_01_band3.csv not found."
     ]
    }
   ],
   "source": [
    "def H8_Process(ACCOUNT,PW,Band,Band_number,Date):\n",
    "    data = H8_data(ACCOUNT,PW,Band,Band_number,Date).read_H8data()\n",
    "    return data\n",
    "\n",
    "    \n",
    "def JAXA_Process(ACCOUNT,YYYY,MM,DD,HH):\n",
    "    JAXA = JAXA_data(ACCOUNT,YYYY,MM,DD,HH)\n",
    "    AOT550,Aerosol_type = JAXA.read_JAXA()\n",
    "    return AOT550,Aerosol_type\n",
    "\n",
    "\n",
    "def remove_original_file(path):\n",
    "    subprocess.Popen('rm -rf {}'.format(path))\n",
    "    \n",
    "    \n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path) \n",
    "    if not folder:\n",
    "        os.makedirs(path)\n",
    "\n",
    "def calculate_6s_band3(i):\n",
    "    Aero_input = Aerosol_type[i,:]\n",
    "    WV_input = WV[i,:]\n",
    "    OZ_input = OZ[i,:]\n",
    "    AOT550_input = AOT550[i,:]\n",
    "    RAA_input = RAA[i,:]\n",
    "    SZA_input = AHI_SZA[i,:]\n",
    "    view_zM_input = AHI_VZA[i,:]\n",
    "    xi = np.array([Aero_input,WV_input,OZ_input,AOT550_input,RAA_input,SZA_input,view_zM_input])\n",
    "    xi = xi.T\n",
    "    xa = fn1(xi)\n",
    "    xb = fn2(xi)\n",
    "    xc = fn3(xi)\n",
    "    y = xa*AHI_data[i,:]-xb\n",
    "    SR = y/(1+xc*y)\n",
    "    return SR\n",
    "\n",
    "sza = np.linspace(0,80,17)\n",
    "vza = np.linspace(0,80,17)\n",
    "water = np.linspace(0,7,8)\n",
    "ozone = np.linspace(0.2,0.4,5)\n",
    "AOT = np.array([0.01,0.05,0.1,0.15,0.2,0.3,0.4,0.6,0.8,1.0,1.5,2.0])\n",
    "raa = np.linspace(0,180,19)\n",
    "aero_type = np.array([0,1])\n",
    "\n",
    "row_AHI = int((u_lat - d_lat) / res)\n",
    "col_AHI = int((r_lon - l_lon) / res)\n",
    "\n",
    "row_u_AHI = int((60 - u_lat)/res)\n",
    "col_l_AHI = int((l_lon - 85)/res)\n",
    "\n",
    "\n",
    "lat_x = np.linspace(u_lat,d_lat + res,row_AHI)\n",
    "lon_y = np.linspace(l_lon,r_lon - res,col_AHI)\n",
    "\n",
    "\n",
    "row_4KM = int((u_lat - d_lat) / 0.04)\n",
    "col_4KM = int((r_lon - l_lon) / 0.04)\n",
    "\n",
    "row_u_4KM = int((60 - u_lat)/0.04)\n",
    "col_l_4KM = int((l_lon - 85)/0.04)\n",
    "\n",
    "fn1,fn2,fn3 = LUT_interpolation(LUT_PATH).LUT_interpolation()\n",
    "\n",
    "with open(VZA_PATH,'rb') as fp:\n",
    "    AHI_VZA = np.frombuffer(fp.read()).reshape(24000,24000)[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "with open(VAA_PATH,'rb') as fp:\n",
    "    AHI_VAA = np.frombuffer(fp.read()).reshape(24000,24000)[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing 201801070620\n"
     ]
    }
   ],
   "source": [
    "for m in range(len(MM)):\n",
    "    for d in range(len(DD)):\n",
    "        for h in range(len(HH)):\n",
    "            for mi in range(len(MIN)):\n",
    "                start_time = T.time()\n",
    "                date = YYYY+MM[m]+DD[d]+HH[h]+MIN[mi]\n",
    "                time = HH[h] + MIN[mi]\n",
    "\n",
    "                print(\"start processing {}\".format(date))\n",
    "                # make dir\n",
    "                folder_original = target+date+'_original/'\n",
    "                folder_AC = target+date+'_AC/'\n",
    "                mkdir(folder_original)\n",
    "                mkdir(folder_AC)\n",
    "                # Download AHI\n",
    "                AHI_data = H8_Process('liwei','liwei000','ext','01',date)\n",
    "#                 if AHI_data == 'No data':\n",
    "#                     continue\n",
    "        \n",
    "#                     # Solar angle\n",
    "#                 # AHI_SZA = AHI_angle_Process(date,'sza')\n",
    "#                 # AHI_SAA = AHI_angle_Process(date,'saa')\n",
    "#                 AHI_SZA,AHI_SAA = AHI_angle.read_angle_data(date)\n",
    "#                 if AHI_SZA == 'No data' or AHI_SAA == 'No data':\n",
    "#                     continue\n",
    "                    \n",
    "#                 RAA = abs(AHI_SAA - AHI_VAA)\n",
    "#                 RAA[RAA>180]=360-RAA[RAA>180]    \n",
    "#                 AOT550,Aerosol_type = JAXA_Process('liwei1997_chiba-u.jp',YYYY,MM[m],DD[d],HH[h])\n",
    "#                 OZ,WV = CAMS_data(MM[m],HH[h]).read_CAMS()\n",
    "                \n",
    "#                 SR = Parallel(n_jobs=-1)(delayed(calculate_6s_band3)(i) for i in range(row_AHI))\n",
    "#                 # Save file and remove download input data\n",
    "#                 SR=np.array(SR).reshape(row_AHI,col_AHI)\n",
    "#                 SR_file=open(folder_AC+'/'+date+'_b03.dat','wb')\n",
    "#                 SR.astype('f4').tofile(SR_file)\n",
    "#                 SR_file.close()\n",
    "# #                 remove_original_file(folder_original)\n",
    "#                 end_time=T.time()\n",
    "#                 TIME=end_time-start_time\n",
    "#                 print('time: {:.1f} secs, {:.1f} mins,{:.1f} hours'.format(TIME,TIME/60,TIME/3600))\n",
    "#                 print(\"delete file finish\")\n",
    "                    \n",
    "                    \n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
