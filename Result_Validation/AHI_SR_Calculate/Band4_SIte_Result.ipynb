{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as T\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.interpolate import griddata,interpn,RegularGridInterpolator\n",
    "import math\n",
    "import os\n",
    "import datetime\n",
    "import cv2\n",
    "from ftplib import FTP\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "import paramiko\n",
    "from scp import SCPClient\n",
    "import subprocess\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "sza = np.linspace(0,80,17)\n",
    "vza = np.linspace(0,80,17)\n",
    "water = np.linspace(0,7,8)\n",
    "ozone = np.linspace(0.2,0.4,5)\n",
    "AOT = np.array([0.01,0.05,0.1,0.15,0.2,0.3,0.4,0.6,0.8,1.0,1.5,2.0])\n",
    "raa = np.linspace(0,180,19)\n",
    "al = np.linspace(0,8,5)\n",
    "aero_type = np.array([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read MATCHING RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   \n",
    "class H8_data:\n",
    "\n",
    "    def __init__(self , account , pw , band , band_number , date):\n",
    "        self.account = account\n",
    "        self.pw = pw\n",
    "        self.band = band\n",
    "        self.band_number = band_number\n",
    "        self.date = date\n",
    "    \n",
    "    def get_path(self):\n",
    "        return '/data01/GEO/ORGDATA/H8AHI/hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/' + self.date[0:6] + '/' + self.band.upper() + '/'\n",
    "\n",
    "    def get_filename(self):\n",
    "        return self.date + \".\" + self.band + \".\" + self.band_number + \".fld.geoss.bz2\"\n",
    "    \n",
    "    def DN2TBB(self,data):\n",
    "        LUT=np.loadtxt(DN_PATH + 'count2tbb_v102/' + self.band + \".\" + self.band_number)\n",
    "        return LUT[data,1]\n",
    "    \n",
    "    def file_path(self):\n",
    "        return self.get_path() + self.get_filename() \n",
    "                 \n",
    "    def download_H8data(self):\n",
    "        client = paramiko.SSHClient()\n",
    "        client.load_system_host_keys()\n",
    "        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        client.connect(hostname='10.4.123.47', port=22, username=self.account, password=self.pw)\n",
    "        scp = SCPClient(client.get_transport())\n",
    "        sftp = client.open_sftp()\n",
    "\n",
    "        try :\n",
    "            sftp.stat(self.file_path())\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(\"File Not Found\")\n",
    "            return 'No data'\n",
    "\n",
    "        else:\n",
    "            scp.get(self.file_path(), folder_original+'/')\n",
    "            p = subprocess.Popen('lbzip2 -d {}{}'.format(folder_original+'/',self.file_path()[-33:]),shell=True)\n",
    "            p.communicate()\n",
    "            print ('Himawari8/AHI data Processed Finish')\n",
    "            return folder_original + '/' + self.get_filename()[:-4]\n",
    "            \n",
    "    def read_H8data(self):\n",
    "        H8_file_path = self.download_H8data()\n",
    "        if self.band == \"vis\":\n",
    "            sr = 12000\n",
    "        elif self.band == \"ext\":\n",
    "            sr = 24000\n",
    "        else:\n",
    "            sr = 6000\n",
    "        if H8_file_path != 'No data':\n",
    "            with open(H8_file_path,'rb') as fp:\n",
    "                data = np.frombuffer(fp.read(),dtype='>u2').reshape(sr,sr)\n",
    "                data = self.DN2TBB(data)\n",
    "                data = data/100\n",
    "\n",
    "            print(\"data reading finish\")\n",
    "            return data[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "        else:\n",
    "            return 'No data'\n",
    "class LUT_interpolation:\n",
    "    def __init__(self,LUT_PATH):\n",
    "        self.LUT_path = LUT_PATH\n",
    "    \n",
    "    def LUT_interpolation(self):\n",
    "        X1 = np.loadtxt(self.LUT_path + \"01_band4.csv\",delimiter=\",\").reshape(2,8,12,5,17,17,19)\n",
    "        X2 = np.loadtxt(self.LUT_path + \"02_band4.csv\",delimiter=\",\").reshape(2,8,12,5,17,17,19)\n",
    "        X3 = np.loadtxt(self.LUT_path + \"03_band4.csv\",delimiter=\",\").reshape(2,8,12,5,17,17,19)\n",
    "        # return X1, X2, X3\n",
    "        \n",
    "        fn1 = RegularGridInterpolator((aero_type,water,AOT,al,sza,vza,raa),X1,bounds_error=False,fill_value=np.nan)\n",
    "        fn2 = RegularGridInterpolator((aero_type,water,AOT,al,sza,vza,raa),X2,bounds_error=False,fill_value=np.nan)\n",
    "        fn3 = RegularGridInterpolator((aero_type,water,AOT,al,sza,vza,raa),X3,bounds_error=False,fill_value=np.nan)\n",
    "        return fn1,fn2,fn3\n",
    "        \n",
    "\n",
    "class AHI_angle:\n",
    "    def __init__(self,date):\n",
    "        self.date = date        \n",
    "    def read_angle_data(self):\n",
    "        \n",
    "        AHI_date = self.date[4:11]\n",
    "        \n",
    "        sza_file_name = 'AHI_SZA_2020{}5.dat'.format(AHI_date)\n",
    "        saa_file_name = 'AHI_SAA_2020{}5.dat'.format(AHI_date)\n",
    "        \n",
    "        with open(SZA_PATH + sza_file_name,'rb') as fp:\n",
    "            AHI_SZA = np.frombuffer(fp.read(),dtype='u2').reshape(3000,3000)[row_u_4KM:row_u_4KM + row_4KM , col_l_4KM:col_l_4KM + col_4KM] / 100\n",
    "            AHI_SZA=cv2.resize(np.array(AHI_SZA,dtype='float64'),(row_AHI,col_AHI),interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        with open(SAA_PATH + saa_file_name,'rb') as fp:\n",
    "            AHI_SAA = np.frombuffer(fp.read(),dtype='u2').reshape(3000,3000)[row_u_4KM:row_u_4KM + row_4KM , col_l_4KM:col_l_4KM + col_4KM] / 100\n",
    "            AHI_SAA=cv2.resize(np.array(AHI_SAA,dtype='float64'),(row_AHI,col_AHI),interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        return AHI_SZA,AHI_SAA\n",
    "\n",
    "class CAMS_data:\n",
    "    def __init__(self,YYYY,MM,DD,HH,MIN):\n",
    "        self.YYYY = YYYY\n",
    "        self.MM = MM\n",
    "        self.DD = DD\n",
    "        self.HH = HH\n",
    "        self.MIN = MIN\n",
    "        \n",
    "    def read_CAMS(self):\n",
    "        \n",
    "        dtime = dt.datetime(int(self.YYYY),int(self.MM),int(self.DD),int(self.HH),int(self.MIN)+5)\n",
    "        ds = xr.open_dataset(CAMS_PATH + self.YYYY + self.MM + self.DD + '.nc')\n",
    "        ds = ds.interp(time = dtime,method = 'linear')\n",
    "        ds = ds.interp(longitude=lon_y,latitude=lat_x,method=\"nearest\")\n",
    "        \n",
    "        OZ = ds['gtco3'].values        \n",
    "        WV = ds['tcwv'].values        \n",
    "        AOT550 = ds['aod550'].values\n",
    "#         Atmosphere data Unit conversion\n",
    "        WV = WV/10\n",
    "        OZ = OZ*46.6975764\n",
    "\n",
    "\n",
    "#         Processing water vapor and ozone max and min\n",
    "        OZ[OZ>=max(ozone)] = max(ozone)-(1/10000)\n",
    "        OZ[OZ<=min(ozone)] = min(ozone)+(1/10000)\n",
    "        WV[WV>=max(water)] = max(water)-(1/10000)\n",
    "        WV[WV<=min(water)] = min(water)+(1/10000)\n",
    "        AOT550[AOT550>=max(AOT)] = max(AOT)-(1/10000)\n",
    "        AOT550[AOT550<=min(AOT)] = min(AOT)+(1/10000)\n",
    "        \n",
    "        return np.array(OZ).reshape(row_AHI,col_AHI),np.array(WV).reshape(row_AHI,col_AHI),np.array(AOT550).reshape(row_AHI,col_AHI)\n",
    "\n",
    "    def read_CAMS_AERO(self):\n",
    "        \n",
    "        dtime = dt.datetime(int(self.YYYY),int(self.MM),int(self.DD),int(self.HH),int(self.MIN)+5)\n",
    "        \n",
    "        ds = xr.open_dataset(CAMS_AERO_PATH + self.YYYY + self.MM + self.DD + '.nc')\n",
    "        ds = ds.interp(time = dtime,method = 'linear')\n",
    "        ds = ds.interp(longitude=lon_y,latitude=lat_x,method=\"nearest\")\n",
    "        \n",
    "        bc = ds['bcaod550'].values\n",
    "        du = ds['duaod550'].values\n",
    "        om = ds['omaod550'].values\n",
    "        ss = ds['ssaod550'].values\n",
    "        su = ds['suaod550'].values\n",
    "\n",
    "        DL_6S = np.array(du)\n",
    "        SL_6S = np.array(su) + np.array(bc)\n",
    "        OC_6S = np.array(ss)\n",
    "        WS_6S = np.array(om)\n",
    "\n",
    "        Total = DL_6S + SL_6S + OC_6S + WS_6S\n",
    "\n",
    "        precent_DL_6S = DL_6S / Total\n",
    "        precent_SL_6S = SL_6S / Total\n",
    "        precent_OC_6S = OC_6S / Total\n",
    "        precent_WS_6S = WS_6S / Total\n",
    "        P = np.dstack((precent_DL_6S,precent_WS_6S,precent_OC_6S,precent_SL_6S))\n",
    "        Aerosol_type = np.where(np.amax(P,axis = 2) == precent_OC_6S,1,0)\n",
    "        \n",
    "        return Aerosol_type\n",
    "\n",
    "def H8_Process(ACCOUNT,PW,Band,Band_number,Date):\n",
    "    data = H8_data(ACCOUNT,PW,Band,Band_number,Date).read_H8data()\n",
    "    return data\n",
    "\n",
    "# def remove_original_file(path):\n",
    "#     subprocess.Popen('rm -rf {}'.format(path))\n",
    "    \n",
    "    \n",
    "def mkdir(path):\n",
    "    folder = os.path.exists(path) \n",
    "    if not folder:\n",
    "        os.makedirs(path)\n",
    "        \n",
    "def Time_split(time):\n",
    "    YYYY = time.strftime('%Y')\n",
    "    MM = time.strftime('%m')\n",
    "    DD = time.strftime('%d')\n",
    "    HH = time.strftime('%H')\n",
    "    MIN = time.strftime('%M')\n",
    "    date = YYYY + MM + DD + HH + MIN\n",
    "    return YYYY,MM,DD,HH,MIN,date\n",
    "        \n",
    "        \n",
    "def calculate_6s_band4(i):\n",
    "    Aero_input = Aerosol_type[i,:]\n",
    "    WV_input = WV[i,:]\n",
    "    AOT550_input = AOT550[i,:]\n",
    "    RAA_input = RAA[i,:]\n",
    "    SZA_input = AHI_SZA[i,:]\n",
    "    VZA_input = AHI_VZA[i,:]\n",
    "    AL_input = AHI_AL[i,:]\n",
    "    xi = np.array([Aero_input,WV_input,AOT550_input,AL_input,SZA_input,VZA_input,RAA_input])\n",
    "    xi = xi.T\n",
    "    xa = fn1(xi)\n",
    "    xb = fn2(xi)\n",
    "    xc = fn3(xi)\n",
    "    y = xa*AHI_data[i,:]-xb\n",
    "    SR = y/(1+xc*y)\n",
    "    return SR\n",
    "\n",
    "\n",
    "\n",
    "fn1,fn2,fn3 = LUT_interpolation(LUT_PATH).LUT_interpolation()\n",
    "\n",
    "\n",
    "# for date_start in d_ahi:\n",
    "#     start_time = T.time()\n",
    "#     date_time_now = dt.datetime.strptime(date_start, \"%Y-%m-%d %H:%M\")\n",
    "#     # date_dl_str = date_time_now.strftime(\"%Y-%m-%d %H:%M\" )\n",
    "#     YYYY,MM,DD,HH,MIN,date= Time_split(date_time_now)    \n",
    "#     print(\"start processing {}\".format(date))\n",
    "#     # make dir\n",
    "#     folder_original = target + date +'_original/'\n",
    "#     folder_AC = target+date+'_AC/'\n",
    "#     mkdir(folder_AC)\n",
    "#     # Download AHI\n",
    "#     AHI_data = H8_Process('liwei','liwei00','vis','03',date)\n",
    "    \n",
    "#     if AHI_data == 'No data':\n",
    "#         continue\n",
    "\n",
    "#     # Solar angle\n",
    "#     print('Start reading Angle data')\n",
    "#     AHI_SZA,AHI_SAA = AHI_angle(date).read_angle_data()\n",
    "    \n",
    "#     RAA = abs(AHI_SAA - AHI_VAA)\n",
    "#     RAA[RAA>180]=360-RAA[RAA>180]\n",
    "    \n",
    "#     print('Angle data read finished')\n",
    "#     print('Start reading Atmospheric data')\n",
    "#     OZ,WV,AOT550 = CAMS_data(YYYY,MM,DD,HH,MIN).read_CAMS()\n",
    "#     Aerosol_type = CAMS_data(YYYY,MM,DD,HH,MIN).read_CAMS_AERO()\n",
    "#     print('Atmospheric data read finished')\n",
    "    \n",
    "#     SR = Parallel(n_jobs=-1)(delayed(calculate_6s_band4)(i) for i in range(row_AHI))\n",
    "#     # Save file and remove download input data\n",
    "#     SR=np.array(SR).reshape(row_AHI,col_AHI)\n",
    "#     SR_file=open(folder_AC+'/'+date+'_b04.dat','wb')\n",
    "#     SR.astype('f4').tofile(SR_file)\n",
    "#     SR_file.close()\n",
    "# #                 remove_original_file(folder_original)\n",
    "#     end_time=T.time()\n",
    "#     TIME=end_time-start_time\n",
    "#     print('time: {:.1f} secs, {:.1f} mins,{:.1f} hours'.format(TIME,TIME/60,TIME/3600))\n",
    "#     print(\"delete file finish\")\n",
    "    \n",
    "    \n",
    "#     date_time_now = date_time_now + date_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SET PATH AND ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "target ='/data01/people/liwei/Data/AHI_Validation/'\n",
    "\n",
    "SZA_PATH = '/data01/GEO/INPUT/ANGLE/Solar_Zenith_Angle_u2/'\n",
    "SAA_PATH = '/data01/GEO/INPUT/ANGLE/Solar_Azimuth_Angle_u2/'\n",
    "VZA_PATH = '/data01/GEO/INPUT/ANGLE/Viewer_Zenith_Angle/AHI_VZA_10.dat'\n",
    "VAA_PATH = '/data01/GEO/INPUT/ANGLE/Viewer_Azimuth_Angle/AHI_VAA_10.dat'\n",
    "\n",
    "LUT_PATH = '/data01/GEO/INPUT/LUT/'\n",
    "CAMS_PATH = '/data01/GEO/INPUT/ATMOSPHERE/'\n",
    "DN_PATH = '/data01/GEO/INPUT/'\n",
    "CAMS_AERO_PATH = '/data01/GEO/INPUT/AEROSOL_TYPE/'\n",
    "AL_PATH = '/data01/GEO/INPUT/ELEVATION_GEO/AHI/MERIT_DEM_AHI_10km.dat'\n",
    "\n",
    "YYYY = '2020'\n",
    "\n",
    "# site_name = 'ROI 1'\n",
    "# site = [16.75,96.5]\n",
    "\n",
    "# site_name = 'ROI 3'\n",
    "# site = [27,96.5] # ROI 3\n",
    "\n",
    "# site_name = 'ROI 6'\n",
    "# site = [46,114]\n",
    "\n",
    "# site_name = 'ROI 8'\n",
    "# site = [42.990,107.043]\n",
    "\n",
    "# site_name = 'ROI 9'\n",
    "# site = [41.7,104.6]\n",
    "\n",
    "# site_name = 'ROI 10'\n",
    "# site = [49.6,119.4]\n",
    "\n",
    "# site_name = 'ROI 11'\n",
    "# site = [40.74,102.48]\n",
    "\n",
    "# site_name = 'ROI 12'\n",
    "# site = [43.72,115.59]\n",
    "\n",
    "res = 0.01\n",
    "\n",
    "u_lat,d_lat = site[0]+0.06,site[0]-0.06\n",
    "l_lon,r_lon = site[1]-0.06,site[1]+0.06\n",
    "\n",
    "row_AHI = round((u_lat - d_lat) / res)\n",
    "col_AHI = round((r_lon - l_lon) / res)\n",
    "\n",
    "row_u_AHI = round((60 - u_lat)/res)\n",
    "col_l_AHI = round((l_lon - 85)/res)\n",
    "\n",
    "\n",
    "lat_x = np.linspace(u_lat,d_lat + res,row_AHI)\n",
    "lon_y = np.linspace(l_lon,r_lon - res,col_AHI)\n",
    "\n",
    "\n",
    "row_4KM = round((u_lat - d_lat) / 0.04)\n",
    "col_4KM = round((r_lon - l_lon) / 0.04)\n",
    "\n",
    "row_u_4KM = round((60 - u_lat)/0.04)\n",
    "col_l_4KM = round((l_lon - 85)/0.04)\n",
    "\n",
    "\n",
    "with open(VZA_PATH,'rb') as fp:\n",
    "    AHI_VZA = np.frombuffer(fp.read(),dtype='u2').reshape(12000,12000)[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "    AHI_VZA = AHI_VZA / 100\n",
    "with open(VAA_PATH,'rb') as fp:\n",
    "    AHI_VAA = np.frombuffer(fp.read(),dtype='u2').reshape(12000,12000)[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "    AHI_VAA = AHI_VAA / 100\n",
    "with open(AL_PATH ,'rb') as fp:\n",
    "    AHI_AL = np.frombuffer(fp.read(),dtype='u2').reshape(12000,12000)[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "    AHI_AL = AHI_AL / 1000\n",
    "\n",
    "\n",
    "d_ahi = []\n",
    "with open(\"/data01/people/liwei/Data/Matching_Result/{}_{}_PL.txt\".format(site_name,YYYY), \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n') \n",
    "        if line[0:8] == 'AHI TIME':\n",
    "            ahi = line[9:13]+ '-' +line[14:16]+ '-' +line[17:19]+ ' ' +line[20:22]+ ':' +line[23:25]\n",
    "            \n",
    "            d_ahi.append(ahi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202005/VIS/202005140410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202005/VIS/202005290410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202006/VIS/202006130410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202006/VIS/202006170410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202006/VIS/202006280410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202007/VIS/202007020410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202007/VIS/202007130410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202007/VIS/202007170410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202007/VIS/202007210410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202008/VIS/202008010410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202008/VIS/202008050410.vis.03.fld.geoss.bz2\n",
      "ftp://hmwr829gr.cr.chiba-u.ac.jp/gridded/FD/V20151105/202008/VIS/202008240400.vis.03.fld.geoss.bz2\n"
     ]
    }
   ],
   "source": [
    "ws = '/data01/people/liwei/Data/2021_AHI'\n",
    "download = []\n",
    "with open(\"/data01/people/liwei/Data/Matching_Result/{}_{}_PL.txt\".format(site_name,YYYY), \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n') \n",
    "        if line[0:8] == 'AHI TIME':\n",
    "            ahi = [line[9:13],line[14:16],line[17:19],line[20:22],line[23:25]]\n",
    "            download.append(\"\".join(ahi))\n",
    "for date in download:\n",
    "    ahi_data_time = date\n",
    "    ahi_data_folder1 = ahi_data_time[:6]\n",
    "    ahi_data_folder2 = ahi_data_folder1[:8]\n",
    "    ahi_saa_filename = ahi_data_time + '.vis.03.fld.geoss.bz2'\n",
    "    ahi_saa_path = '/gridded/FD/V20151105/' + ahi_data_folder1 + '/VIS/' + ahi_saa_filename\n",
    "    ftp_dl_url = 'ftp://hmwr829gr.cr.chiba-u.ac.jp' + ahi_saa_path\n",
    "    print(ftp_dl_url)\n",
    "    ftp = FTP()\n",
    "    ftp.connect('hmwr829gr.cr.chiba-u.ac.jp', 21)\n",
    "    ftp.login()\n",
    "    local_file = ws + '/' + ahi_saa_filename\n",
    "    with open(local_file, 'wb') as f:\n",
    "        ftp.retrbinary('RETR ' + ahi_saa_path, f.write, 1024*1024)\n",
    "    p = subprocess.Popen('lbzip2 -d {}'.format(local_file),shell=True)\n",
    "    p.communicate()    \n",
    "\n",
    "ftp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start processing 202005140410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 2.0 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202005290410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 2.2 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202006130410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 2.2 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202006170410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.9 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202006280410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.7 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202007020410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.7 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202007130410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.9 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202007170410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.7 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202007210410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.9 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202008010410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.7 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202008050410\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 1.7 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n",
      "start processing 202008240400\n",
      "Start reading Angle data\n",
      "Angle data read finished\n",
      "Start reading Atmospheric data\n",
      "Atmospheric data read finished\n",
      "time: 2.0 secs, 0.0 mins,0.0 hours\n",
      "delete file finish\n"
     ]
    }
   ],
   "source": [
    "def DN2TBB(data):\n",
    "    LUT=np.loadtxt(DN_PATH + 'count2tbb_v102/vis.03')\n",
    "    return LUT[data,1]\n",
    "\n",
    "for date_start in d_ahi:\n",
    "    start_time = T.time()\n",
    "    date_time_now = dt.datetime.strptime(date_start, \"%Y-%m-%d %H:%M\")\n",
    "    # date_dl_str = date_time_now.strftime(\"%Y-%m-%d %H:%M\" )\n",
    "    YYYY,MM,DD,HH,MIN,date= Time_split(date_time_now)    \n",
    "    print(\"start processing {}\".format(date))\n",
    "    # make dir\n",
    "    folder_AC = target+date+'_AC/'\n",
    "    mkdir(folder_AC)\n",
    "    # Download AHI\n",
    "    with open(ws + '/{}.vis.03.fld.geoss'.format(date),'rb') as fp:\n",
    "        data = np.frombuffer(fp.read(),dtype='>u2').reshape(12000,12000)\n",
    "        data = DN2TBB(data)\n",
    "        data = data/100\n",
    "        \n",
    "    AHI_data = data[row_u_AHI:row_u_AHI + row_AHI , col_l_AHI:col_l_AHI + col_AHI]\n",
    "\n",
    "    # Solar angle\n",
    "    print('Start reading Angle data')\n",
    "    AHI_SZA,AHI_SAA = AHI_angle(date).read_angle_data()\n",
    "    \n",
    "    RAA = abs(AHI_SAA - AHI_VAA)\n",
    "    RAA[RAA>180]=360-RAA[RAA>180]\n",
    "    \n",
    "    print('Angle data read finished')\n",
    "    print('Start reading Atmospheric data')\n",
    "    OZ,WV,AOT550 = CAMS_data(YYYY,MM,DD,HH,MIN).read_CAMS()\n",
    "    Aerosol_type = CAMS_data(YYYY,MM,DD,HH,MIN).read_CAMS_AERO()\n",
    "    print('Atmospheric data read finished')\n",
    "    \n",
    "    SR = Parallel(n_jobs=-1)(delayed(calculate_6s_band4)(i) for i in range(row_AHI))\n",
    "    # Save file and remove download input data\n",
    "    SR=np.array(SR).reshape(row_AHI,col_AHI)\n",
    "    SR_file=open(folder_AC+'/'+date+'_'+ site_name +'_b04.dat','wb')\n",
    "    SR.astype('f4').tofile(SR_file)\n",
    "    SR_file.close()\n",
    "#                 remove_original_file(folder_original)\n",
    "    end_time=T.time()\n",
    "    TIME=end_time-start_time\n",
    "    print('time: {:.1f} secs, {:.1f} mins,{:.1f} hours'.format(TIME,TIME/60,TIME/3600))\n",
    "    print(\"delete file finish\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
